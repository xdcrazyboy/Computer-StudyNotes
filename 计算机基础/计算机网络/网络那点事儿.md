# 网络那点事
[TOC]

# TCP/IP协议

## TCP介绍

其实不管哪一层的协议，协议包含的报头信息一般都有： 
- 源地址，目标地址，TCP是端口号。我要知道地方才能传输呀；
- 上一层用的的协议，肯定得懂规矩。 
- 数据：什么本层报头，上一层报头，上一层数据....； 
- 对了，当初因为传输不靠谱，一般都有个校验值。

IP协议：
    - TTL 数据报的生存时间，可经过的最多路由器总数。没经过一个路由器，该值减1，为0就丢弃该报文，并发送 **ICMP**报文通知源主机，防止其一直发送报文。
        >ICMP是检测传输网络是否通畅、主机是否可达、路由是否可用等网 络运行状态的协议。  
        >虽然并不传输用户数据，但是对评估网络健康状态非常重 要，经常使用的 ping、 tracert 命令就是基于 ICMP 检测网络状态的有力工具。

### TCP与UDP
传输层： TCP可靠，UDP不可靠
- TCP使用：`fd = socket(AF_INET,SOCK_STREAM,0);`
  - 其中SOCK_STREAM，是指使用字节流传输数据，就是TCP协议。这也是TCP基于字节流的题中之义，UDP是面向数据包。TCP还有两个特点：可靠、面向连接
  - 在定义了socket之后，我们就可以愉快的对这个socket进行操作，比如用bind()绑定IP端口，用connect()发起建连。之后就可以recv()和send（）接发数据了


#### TCP基于字节流

- 字节流可以理解为一个双向的通道里流淌的数据，这个数据其实就是我们常说的二进制数据，简单来说就是一大堆 01 串。
- 纯裸TCP收发的这些 01 串之间是**没有任何边界**的，你根本不知道到哪个地方才算一条完整消息，这就是所谓的**粘包问题**。
- **所以需要约定个规则去区分这些01串的边界、含义**——这就是上层协议，于是基于TCP，就衍生了非常多的协议，比如HTTP和RPC（这些是定义了不同消息格式的应用层协议）。
  - 比如约定消息头，消息头里写清楚一个完整的包长度是多少、消息体是否被压缩过和消息体格式之类的，只要上下游都约定好了，互相都认就可以了，这就是所谓的**协议**。



## 三次握手 & 四次挥手

### 三次握手
- 信息对等
  > 第三次握手后：B机器才能确认自己的发报能力和对方的收报能力
- 防止超时
  > **这些都是源于报文可能丢失！！！或者迷路慢了。** TTL网络报文的生存时间 > TCP请求超时时间 ==> 两次握手建立连接的话，第一次连接请求慢到了，但是第二次重试连接成功，而且通信结束，顺便关闭连接了，（此时A已经不是SYN_SENT，不会接收请求）这第一次迷路的连接请求才到，B机器就以为A要跟他建立新连接，跟A发确认数据，A会直接丢掉，B就苦苦等待，也就是出现脏连接。

### 四次挥手 
1. A FIN=1，告诉B我准备分手了。 A现在是待分手（半关闭状态 FIN_WAIT_1）
2. B ACK=1 , 告诉B 分手就分手，谁怕谁！就是有点突然，等我准备一下（处理完数据）。B现在是待分手（半关闭状态 CLOSE_WAIT）A收到ACK进入FIN_WAIT_2（如果B这渣男不需要准备，直接发ACK、FIN），A可以直接跳过这个状态进入3中的TIME_WAIT
3. B FIN=1、ACK=1，主动告诉B，我做好准备了，随手可以分手。B现在是LAST_ACK
4. A ACK=1，确定了对方也做好分手的准备了，最后一次告诉你，分手吧不用回。 A现在是TIME_WAIT（顾名思义等某个时间），等两个月（2MSL），还没收到B的挽回消息，那就能确定，B收到了A最后的分手通牒。 **正式分手成功！！**

- 这个MSL其实挺长的，在当前告诉网络，这是非常耗时的，在高并发等服务器上这是浪费资源。但是为什么还非要等呢？
    1. 确认被动关闭放能顺利进入CLOSED状态，B表示 我被分手但是不甘心，没收到你的最后通牒我是不会死心的。 如果你不给我时间，我可能就会一直拖着。
    2. 防止失效请求。
- TIME_WAIT状态下是无法释放句柄资源的，高并发服务器上会极大限制有效连接的数量，成为性能瓶颈。所以， **建议将高并发服务器的TIME_WAIT超时时间调小**。 （小于30秒为宜），怎么改？ `/etc/sysctl.conf`，修改值


### QUIC 是如何解决TCP 性能瓶颈的？
TCP 队头阻塞的主要原因是数据包超时确认或丢失阻塞了当前窗口向右滑动，我们最容易想到的解决队头阻塞的方案是不让超时确认或丢失的数据包将当前窗口阻塞在原地。

QUIC (Quick UDP Internet Connections)也正是采用上述方案来解决TCP 队头阻塞问题的。



## HTTP


### HTTP1.1

1997年1月，HTTP/1.1 版本发布，只比 1.0 版本晚了半年。它进一步完善了 HTTP 协议，一直用到了20年后的今天，直到现在还是最流行的版本。

- 持久连接
  - TCP连接默认不关闭，可以被多个请求复用，不用声明Connection: keep-alive。
  - 主动关闭：客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。不过，规范的做法是，客户端在最后一个请求时，发送Connection: close，明确要求服务器关闭TCP连接。
- 管道机制
  - 在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。服务器还是按照顺序回应。
- Content-Length 字段
  - 一个TCP连接现在可以传送多个回应，势必就要有一种机制，区分数据包是属于哪一个回应的。这就是Content-length字段的作用，声明本次回应的数据长度。
- 分块传输编码
  - 长度放在最前面，那就要在所有数据确认完后再发送，这意味着，服务器要等到所有操作完成，才能发送数据。太低效了。
  - 改进：产生一块数据，就发送一块，采用"流模式"（stream）取代"缓存模式"（buffer）。
    - 只要请求或回应的头信息有Transfer-Encoding字段，就表明回应将由数量未定的数据块组成。`Transfer-Encoding: chunked`.
    - 每个非空的数据块之前，会有一个16进制的数值，表示这个块的长度。最后是一个大小为0的块，就表示本次回应的数据发送完了。
- 客户端请求的头信息新增了Host字段，用来指定服务器的域名。有了Host字段，就可以将请求发往同一台服务器上的不同网站，为虚拟主机的兴起打下了基础。

虽然1.1版允许复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为"队头堵塞"（Head-of-line blocking）。

参考链接：http://www.ruanyifeng.com/blog/2016/08/http.html


### HTTP/2

2015年，HTTP/2 发布。它不叫 HTTP/2.0，因为标准委员会不打算再发布子版本了，下一个新版本将是 HTTP/3。

- **二进制协议**：
  - HTTP/1.1 版的头信息肯定是**文本（ASCII编码）**，数据体可以是文本，也可以是二进制。
  - HTTP/2 则是一个**彻底的二进制协**议，头信息和数据体都是二进制，并且统称为"帧"（frame）：头信息帧和数据帧。
  - 二进制协议的一个好处是，可以定义额外的帧。比如 HEADERS 和 DATA 帧构成了 HTTP 请求和响应的基础；
  - 在 HTTP/2 中定义了 10 种不同类型的帧，每种帧类型都有不同的用途。其它帧类型(比如 PRIORITY、SETTINGS、PUSH_PROMISE、WINDOW_UPDATE 等 )用于支持其它 HTTP/2 功能。 
- **多工（Multiplexing）**: 
  - HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。
  - 举个栗子：在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。这种双向的、实时的通信，就叫做多工（Multiplexing）
- **数据流**：
  - 因为 HTTP/2 的数据包是**不按顺序发送**的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要**对数据包做标记**，指出它属于哪个回应。
  - HTTP/2 将**每个请求**或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的编号。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。
  - 数据流发送到一半的时候，客户端和服务器都可以发送信号（RST_STREAM帧），取消这个数据流。HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。
  - 客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。
- **Header压缩HPACK**：
  - HTTP/2 在客户端与服务器端都维护了一张首部字段索引列表， header 字段列表是以key - value 键值对元素构成的有序集合，每个header 字段元素都映射为一个索引值，报文中使用header 字段的索引值进行二进制编码传输
  - 为了进一步降低header 字段的传输开销，这些 header 字段表可以在编码或解码新 header 字段时进行增量更新，新的header 字段采用Huffman 编码（摩斯电码就采用了霍夫曼编码）可以进一步降低编码后的字节数。
- **服务器推送**:
  - HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。
  - 服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。


**HTTP/2在HTTP1.1基础上做了哪些优化？**

| HTTP/1.1 性能瓶颈  | HTTP/2 改进优化  |
|-------------------|-----------------------------|
| 存在**队头阻塞**问题，降低了TCP连接利用率  | 通过多数据流并发复用TCP连接，不仅解决了队头阻塞问题，还大大提高了TCP连接的利用率   |
| 重复传输**臃肿的首部字段**，降低了网络资源利用率   | 通过**首部压缩**，大大减少了需要传输的首部字段字节数，进一步提高了网络资源利用率   |
| 报文各字段长度不固定，增加了报文解析难度，只能串行解析  | 整个报文都采用二进制编码，且每个字段长度固定，可以**并行处理**，提高了报文处理效率    | 
| 只能客户端发起请求，服务器响应请求，服务器端的数据更新不能及时反馈给客户端 | **支持服务器端向客户端推送资源**，服务器端的数据更新可以及时反馈给客户端，也可以通过**预判客户端需求提前向客户端推送相应资源**，提高客户端的访问响应效率 |


**Binary frame layer**


HTTP/2 使用帧来封装各字段信息，帧中包含表示整帧长度的字段，每个字段也有固定的长度，处理帧协议的程序就能预先知道会收到哪些字段信息，每个字段占用多少内存空间，也就可以并行处理数据帧。

HTTP/2 可以并行处理多个数据帧，再借助Stream Identifier 字段标识每个请求/响应数据流，可以让不同数据流的数据帧交错的在TCP连接上传输（借助Stream ID，即便交错传输也可以重新组装），这就实现了**多个数据流并发复用同一个TCP连接的效果**。

HTTP/2 中定义了 10种不同的帧类型，每种帧类型都有不同的用途，其中 HEADERS 和 DATA 帧构成了 HTTP 请求和响应的基础，这十种帧类型及功能描述如下：

| 帧类型名称         | ID  | 描述                   |
|---------------|-----|----------------------|
| DATA          | 0x0 | 传输流的核心内容             |
| HEADERS       | 0x1 | 包含HTTP 首部，和可选的优先级参数  |
| PRIORITY      | 0x2 | 指示或者更改流的优先级和依赖       |
| RST_STREAM    | 0x3 | 允许一端停止流（通常由于错误导致的）   |
| SETTINGS      | 0x4 | 协商连接级参数              |
| PUSH_PROMISE  | 0x5 | 提示客户端，服务器要推送些东西      |
| PING          | 0x6 | 测试连接可用性和往返时延（RTT）    |
| GOAWAY        | 0x7 | 告诉另一端，当前端已结束         |
| WINDOW_UPDATE | 0x8 | 协商一端将要接收多少字节（用于流量控制）|
| CONTINUATION  | 0x9 | 用以扩展HEADER 数据块       |

**HTTP/2 所有性能增强的核心在于新的二进制分帧层**，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。

### 既然有HTTP协议，为什么还要有RPC

[摘录自小白debug](https://mp.weixin.qq.com/s?__biz=MjM5NTY1MjY0MQ==&mid=2650859827&idx=3&sn=3baa2cdddab891cf90907dabb1985b77&chksm=bd017c7d8a76f56b7cdeed529c44363b7f65de1ad49785fb52aa1c746c0314e4d78282464e2a&scene=27)


**HTTP**

HTTP协议（Hyper Text Transfer Protocol），又叫做超文本传输协议。


**RPC**

RPC（Remote Procedure Call），又叫做远程过程调用。它本身并不是一个具体的协议，而是一种调用方式。

- 想像调用本地方法一样调用远程的方法，屏蔽掉一些网络细节，基于这个思路，大佬们造出了非常多款式的RPC协议，比如比较有名的gRPC，thrift。
- 虽然大部分RPC协议底层使用TCP，但实际上它们不一定非得使用TCP，改用UDP或者HTTP，其实也可以做到类似的功能。gRPC就是用的HTTP2协议，



**TCP是70年代出来**的协议，而**HTTP是90年代**才开始流行的。而直接使用裸TCP会有问题，可想而知，这中间这么多年有多少自定义的协议，而这里面就有**80年代出来的RPC**。问题应该反过来

**那既然有RPC了，为什么还要有HTTP呢？**


**1. HTTP和RPC有什么区别**

- **服务发现**： 想要访问某个服务，就去这些中间服务去获得IP和端口信息。 两者区别不大
  - HTTP：就是寻找IP和端口的过程，用到DNS服务。
  - RPC：一般会有专门的中间服务去保存服务名和IP信息，比如consul或者etcd，甚至是redis。
  - 由于dns也是服务发现的一种，所以也有基于dns去做服务发现的组件，比如CoreDNS。
- **底层连接形式**：
  - HTTP：以主流的HTTP1.1协议为例，其默认在**建立底层TCP连接**之后会一直保持这个连接（keep alive），之后的请求和响应都会**复用**这条连接。对于同一个域名，大多数浏览器允许同时建立6个持久连接。
  - RPC：也是通过**建立TCP长链接**进行数据交互，但不同的地方在于，RPC协议一般还会再建个连接池，在请求量大的时候，建立多条连接放在池内，要发数据的时候就从池里取一条连接出来，用完放回去，下次再复用，可以说非常环保。
  - 由于连接池有利于提升网络请求性能，所以不少编程语言的**网络库里**都会**给HTTP加个连接池**，**比如go**就是这么干的。所以也不算大区别。
- **传输的内容**
  - 也就是消息头header和消息体body，字符串、数字直接就能转成0101，而结构体也有类似json，protobuf这些方案去实现（序列化、反序列化）。
  - HTTP1.1： 主要是传字符串，header和body都是如此。在body这块，它使用json来序列化结构体数据。 
    - header内容冗余，约定好头部的第几位是content-type，就不需要每次都真的把"content-type"这个字段都传过来。
    - body的json也比较冗余
    - HTTP2在前者的基础上做了很多改进，所以**性能可能比很多RPC协议还要好**，甚至连**gRPC底层都直接用的HTTP2**。
  - RPC：因为它定制化程度更高，可以**采用体积更小的protobuf或其他序列化协议**去保存结构体数据，同时也不需要像HTTP那样考虑各种浏览器行为，比如302重定向跳转啥的。因此性能也会更好一些，这也是在公司内部微服务中抛弃HTTP，选择使用RPC的最主要原因。


**为什么既然有了HTTP2，还要有RPC协议？**

HTTP2是2015年才出来，很多公司内部RPC协议跑了很多年了，基于历史原因，一般也没必要去换了。

简单来说成熟的rpc库相对http容器，更多的是封装了“服务发现”，"负载均衡"，“熔断降级”一类面向服务的高级特性。

可以这么理解，rpc框架是面向服务的更高级的封装。

如果把一个http servlet容器上封装一层服务发现和函数代理调用，那它就已经可以做一个rpc框架了。

**所以为什么要用rpc调用?**
因为良好的rpc调用是面向服务的封装，针对服务的可用性和效率等都做了优化。单纯使用http调用则缺少了这些特性。


参考链接：https://www.zhihu.com/question/41609070/answer/191965937


### HTTPS

#### TSL/SSL & 四次挥手



