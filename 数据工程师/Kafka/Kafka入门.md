# Kafka入门指南

## 简单认识下

与大多数消息系统相比，Kafka 具有更好的吞吐量、内置分区、复制和容错能力，这使其成为大规模消息处理应用程序的良好解决方案。



## 概念名词解释
Kafka 是一个**分布式**的，**支持多分区、多副本**，基于**Zookeeper** 的分布式**消息流**平台，它同时也是一款开源的基于**发布订阅**模式的**消息引擎**系统。

- **消息**：Kafka 中的数据单元被称为消息
- **主题**：消息的种类称为 主题（Topic），相当于是对消息进行分类
- **分区**：主题可以被分为若干个分区（partition）
  - 同一个主题中的分区可以不在一个机器上，有可能会部署在多个机器上，由此来实现 kafka 的伸缩性，
  - 单一主题中的分区有序，但是无法保证主题中所有的分区有序
- **生产者**： 向主题发布消息的**客户端**应用程序称为生产者（Producer），生产者用于持续不断的向某个主题发送消息
- **消费者**：订阅主题消息的**客户端**程序称为消费者（Consumer），消费者用于处理生产者产生的消息。
  - **消费者群组**：生产者与消费者的关系就如同餐厅中的厨师和顾客之间的关系一样，一个厨师对应多个顾客，也就是一个生产者对应多个消费者，消费者群组（Consumer Group）指的就是由一个或多个消费者组成的群体。
- **偏移量**：偏移量（Consumer Offset）是一种元数据，它是一个不断递增的整数值，用来记录消费者发生**重平衡**时的位置，以便用来恢复数据。
  - **重平衡**：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。
  
- **broker**: 一个独立的 Kafka 服务器就被称为 broker，broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。Kafka 的**服务器端**。
  - **broker 集群**：broker 是集群 的组成部分，broker 集群由一个或多个 broker 组成，每个集群都有一个 broker 同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。
- **副本**：Kafka 中消息的备份又叫做 副本（Replica），副本的数量是可以配置的，Kafka 定义了两类副本：领导者副本（Leader Replica） 和 追随者副本（Follower Replica），前者对外提供服务，后者只是被动跟随。
>生产者总是向领导者副本写消息;而消费者总是从领导者副本读消息。至于追随者副本，它只做一件事:向领导者副本发送请求，请求领导者把最新生产的消息发给它，这样它能保持与领导者的同步。



### 特性

- `高吞吐、低延迟`：kakfa 最大的特点就是收发消息非常快，kafka 每秒可以处理几十万条消息，它的最低延迟只有几毫秒。
- `高伸缩性`： 每个主题(topic) 包含多个分区(partition)，主题中的分区可以分布在不同的主机(broker)中。
- `持久性、可靠性`： Kafka 能够允许数据的持久化存储，消息被持久化到磁盘，并支持数据备份防止数据丢失，Kafka 底层的数据存储是基于 Zookeeper 存储的，Zookeeper 我们知道它的数据能够持久存储。
- `容错性`： 允许集群中的节点失败，某个节点宕机，Kafka 集群能够正常工作. 
  
- `高并发`： 支持数千个客户端同时读写.

**问：Kafka为什么快？高吞吐？**
* 顺序读写
* 零拷贝
* 消息压缩
* 分批发送


**问： Kafka Broker 是如何持久化数据的？**

Kafka 使用 消息日志(Log)来保存数据，一个日志就是磁盘上一个只能追加写(Append-only)消 息的物理文件。
>因为只能追加写入，故避免了缓慢的随机 I/O 操作，改为性能较好的顺序 I/O 写操作，这也是实现 Kafka 高吞吐量特性的一个重要手段。


**问：Kafka定期删除数据回收磁盘，怎么删除呢？**

**通过日志段(Log Segment)机制**。在 Kafka 底层，一 个日志又近一步细分成多个日志段，消息被追加写到当前最新的日志段中，当写满了一个日 志段后，Kafka 会自动切分出一个新的日志段，并将老的日志段封存起来。

Kafka 在后台还 有**定时任务会定期地检查**老的日志段**是否能够被删除**，从而实现回收磁盘空间的目的。


**再说说消费者**


### 使用场景

### 对比



## 设计思想

### 持久化 & 效率  & 端到端批量压缩
**问：Kafka为什么快？高吞吐？**

**顺序读写** —— 不要害怕系统文件，磁盘很慢？

  * 磁盘顺序写入的性能约为 600MB/秒，而随机写入的性能仅为约 100k/秒——相差超过 6000 倍。几乎达到甚至好于内存随机读取
  * 这些线性读取和写入是所有使用模式中最可预测的，并且由操作系统进行了大量优化。现代操作系统提供预读和后写技术，以大块倍数预取数据，并将较小的逻辑写入分组为大的物理写入。
  * 在某些情况下，顺序磁盘访问可能比随机内存访问更快！磁盘寻到是最耗时的，那就减少寻道。 **而Kafka就是利用这个特性，可以在磁盘存储，即利用了磁盘空间大便宜的特点，让消息敢且能长时间大量存储，又能快速读取。**
  * 持久队列可以建立在简单的读取和附加到文件的基础上，就像日志记录解决方案的常见情况一样。这种结构的优点是所有操作都是 O(1) 并且读取不会阻塞写入或彼此。尽管它们的寻道性能较差，但这些驱动器具有可接受的大型读取和写入性能，而且价格是后者的 1/3，容量是后者的 3 倍。


 **零拷贝**
  * 持久日志块的网络传输。现代 unix 操作系统提供高度优化的代码路径，用于将数据从页面缓存传输到套接字；在 Linux 中，这是通过sendfile 系统调用完成的。
  * 从文件到套接字传输数据的通用数据路径： 四个副本在两个系统间调用，很低效。
    1. 操作系统从磁盘读取数据到内核空间的pagecache
    2. 应用程序从内核空间读取数据到用户空间缓冲区
    3. 应用程序将数据写回内核空间的套接字缓冲区
    4. 操作系统将数据从套接字缓冲区复制到 NIC 缓冲区，并在此处通过网络发送
  - 而使用sendfile，通过允许操作系统将数据从页面缓存直接发送到网络，可以避免这种重新复制。只需要最终拷贝到网卡缓冲区。
  - 我们期望的是：一个主题的多个消费者，能使用上面的零拷贝优化，数据只被复制到页面缓存中一次并在每次消费时重复使用，而不是存储在内存中并在每次读取时复制到用户空间。这可以以接近网络连接限制的速率使用消息。
    >pagecache 和 sendfile 的这种组合意味着在 Kafka 集群上，消费者大部分时间都被捕获，您将看不到磁盘上的任何读取活动，因为它们将完全从缓存中提供数据。


 **消息压缩**
  - 在某些情况下，瓶颈实际上不是 CPU 或磁盘，而是**网络带宽**。
  - Kafka 通过高效的批处理格式支持这一点。一批消息可以聚集在一起压缩并以这种形式发送到服务器。这批消息将以压缩形式写入，并在日志中保持压缩状态，只会被消费者解压。
  - Kafka 支持 GZIP、Snappy、LZ4 和 ZStandard 压缩协议。
  * 另一个低效率是字节复制。在低消息速率下这不是问题，但在负载下影响很大。为了避免这种情况，我们采用了一种由生产者、代理和消费者**共享的标准化二进制消息格式**（因此数据块可以在它们之间传输而无需修改）。


 **分批发送**
  * 减少小IO，为此我们的协议是围绕“**消息集**”抽象构建的，该抽象将消息自然地分组在一起。这允许网络请求将消息组合在一起并分摊网络往返的开销，而不是一次发送一条消息。服务器依次将消息块一次性附加到其日志中，而消费者一次获取大的线性块。


### 生产者

**负载均衡**

- 生产者直接将数据发送到作为分区领导者的代理，而无需任何中间路由层。
- 为了帮助生产者做到这一点，所有 Kafka 节点都可以在任何给定时间回答有关哪些服务器处于活动状态以及主题分区的领导者所在的元数据请求，以允许生产者适当地定向其请求。
- 随机路由，或者指定分区函数路由。比如按照用户ID分区，同一用户的消息都会发送到同一个分区。


**异步发送**

- 批处理是效率的重要驱动因素之一，为了启用批处理，Kafka 生产者将尝试在内存中累积数据并在单个请求中发送更大的批次。批处理可以配置为累积不超过固定数量的消息，并且等待时间不超过某个固定的延迟限制（比如 64k 或 10 毫秒）。
- 积累更多字节发送，一般很少有大IO操作。 不过这种缓存大小可配置，因为需要权衡这带来的额外延迟，目的是获取更好的吞吐量。



### 消费者

**推与拉**

- 基于推送的系统难以处理不同的消费者，因为代理控制数据传输的速率。目标通常是让消费者能够以最大可能的速度消费；在推送系统中，这意味着当消费者的消费率低于生产率时，消费者往往会不知所措（本质上是拒绝服务攻击）。
- 基于拉动的系统具有更好的特性，即消费者可以简单地落后并在可能的时候赶上来。
- 基于拉动的系统的另一个优点是它有助于将发送给消费者的数据积极地分批处理。
- 基于推送的系统必须选择立即发送请求或积累更多数据然后在不知道下游消费者是否能够立即处理它的情况下发送它。


**消费者地位**

- 代理发送完消息是否需要等待消费者确认？
  - 不等待——可能出现消息丢失。 消费者出问题，没处理就奔溃了。
  - 等待—— 解决了丢失问题，但出现了新的问题：
    - 重复消费： 消费者处理了消息但是在发送确认之前失败，那么消息将被消费两次。
    - 性能问题： 代理需要保存每个消息的多个状态（锁定发出去的消息以免二次发送，标记为永久消费以标识可以删除）

如何处理已发送但从未确认的消息？

- 主题分为一组完全有序的分区，每个分区在任何给定时间都由每个订阅消费者组中的一个消费者消费。这意味着消费者在每个分区中的位置只是一个整数，即下一条要消费的消息的偏移量。 已消耗内容的**状态非常小**，每个分区只有一个数字。这使得定期检查此状态的操作十分简单低耗。
- 这个附带有一个好处： 消费者可以故意**回退到旧的偏移量**并**重新消费**数据。这违反了队列的共同约定，但事实证明这是许多消费者的基本特征。


**离线数据加载**

- 可扩展的持久性允许消费者**只定期消费**的可能性，例如**批量数据加载**，周期性地将数据批量加载到离线系统，如 Hadoop 或关系数据仓库。
- 在 Hadoop 的情况下，我们通过将负载拆分到各个映射任务来并行化数据加载，每个映射任务对应一个节点/主题/分区组合，从而允许加载中的完全并行。

**静态成员**

- 静态成员旨在提高流应用程序、消费者组和其他构建在组再平衡协议之上的应用程序的可用性。
- 再平衡协议依赖组协调器将实体 ID 分配给组成员，这些生成的 ID 是短暂的，会在成员重新启动和重新加入时更改。
- 对于基于消费者的应用程序，这种“动态成员资格”可能会导致**在代码部署、配置更新和定期重启**等管理操作期间将大部分任务**重新分配**给不同的实例。对于大型状态应用程序，混洗任务需要**很长时间**才能在处理之前**恢复其本地状**态，并导致应用程序部分或完全不可用。
- Kafka 的组管理协议**允许组成员提供持久的实体 ID**。基于这些id，组成员资格保持不变，因此不会触发重新平衡。


### 消息传递语义

可以提供多种可能的**消息传递保证**：

* 最多一次—**—消息可能会丢失**，但永远不会重新传递。
* 至少一次——消息永远不会丢失，但可能会**重新传递**。
* Exactly once——这正是人们真正想要的，每条消息只传递一次。

这可以分为两个问题： 发布消息的持久性保证和消费消息时的保证。

- kafka不丢数据： 发布消息时，我们有消息被“提交”到日志的概念。一旦发布的消息被提交，只要复制该消息写入的分区的一个代理保持“活动”状态，它就不会丢失。
- 在 0.11.0.0 之前，如果生产者未能收到指示消息已提交的响应，它别无选择，**只能重新**发送消息。 符合至少一次的传递语义。
- 从 0.11.0.0 开始，Kafka 生产者还**支持幂等**传递选项，保证重新发送不会导致日志中出现重复条目​​。
  - 为此，代理为每个生产者分配一个 ID，并使用生产者随每条消息发送的序列号对消息进行重复数据删除。
- 同样从 0.11.0.0 开始，生产者支持使用类似**事务**的语义**将消息发送到多个主题分区的能力**：即要么所有消息都已成功写入，要么都没有。


# 参考资料

- 官网文档： https://kafka.apache.org/documentation.html#design
- 掘金： https://juejin.im/post/6844903495670169607


