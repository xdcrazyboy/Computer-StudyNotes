

# 学习Kafka的正确姿势

## 基本学习路线

**软件工程师**掌握Kafka的路线：
- 第一步，就是要根据你掌握的编程语言去寻找对应的 **Kafka 客户端**。它们更新和维护的速度很快，非常适合你持续花时间投入。
- 第二步，马上去**官网**上学习一下**代码示例**，如果能够**正确编译和运行**这些样例，你就能轻松地驾驭客户端了。
- 第三步，你可以尝试修改样例代码尝试去理解并使用其他的 API，之后观测你修改的结果。
- 第四步，自己编写一个小型项目来验证下学习成果，然后就是改善和提升客户端的可靠性和性能了。 这一步，你可以熟读一遍 Kafka 官网文档，确保你理解的那些可能影响可靠性和性能的参数。
- 最后，学习Kafka的高级功能： 流处理应用开发（时间窗口聚合，流处理连接）


**运维工程师**学习路线：
- 学习如何搭建和管理Kafka线上环境。
- 对生产环境的监控是重中之重。 Kafka提供了超多JMX监控指标，你可以选择任意你熟悉的框架进行监控。
- 有了监控数据，就需要观测真实业务负载下的Kafka集群表现。 根据指标找出系统瓶颈，提升整个系统的吞吐量。



## 基本使用

### 线上方案制定


### 集群配置参数

---
# 一、Kafka入门

## 消息引擎基础

维基百科介绍：消息引擎系统是一组规范。企业利用这组规范在不同系统之间传递语义准确的消息，实现松耦合的异步式数据传递。


**消息的格式**

既然消息引擎是用于**在不同系统之间传输消息**的，那么如何设计待传输**消息的格式**从来都是一等一的大事。试问一条消息如何做到**信息表达业务语义而无歧义**，同时它还要能最大限度地**提供可重用性以及通用性**?

Kafka选择了**纯二进制的字节序列**。当然消息还是结构化的，只是在使用之前都要将其转换成二进制的字节序列。


**消息模型**

点对点模型 vs 发布/订阅模型
-  点对点模型:也叫消息队列模型。 一对一服务， 比如电话客服。
-  发布/订阅模型: 有个topic的概念， 可以存在多个发布者向相同的主题发送消息，订阅者也可以有多个。 比如报纸订阅。

Kafka支持这两种传输方式。


**为啥要用消息引擎，而不是直接系统之间发送？**

- **削峰填谷**
  - 上下游处理消息的逻辑不一样，而速度有慢有快。

- 发送发和接收方的松耦合，一定程度上简化了应用的开发，减少了系统间不必要的交互。


**聪明人也要下死功夫。**

作者说： 在 2015 年那会儿，我花了将近 1 年的时间阅读 Kafka 源代码，期间多次想要放弃。你要知道**阅读将近 50 万行源码是多么痛的领悟**。我还记得当初为了手写源代码注释，自己写满了一个厚厚的笔记本。之前的所有努力也没有白费，以至于后面写书、写极客时间专栏就变成了一件件水到渠成的事情。

## Kafka基本术语

（术语见 《Kafka入门》- 概念名词解释）

消息模型-点对点： 点对点指的是同一条消息只能被下游的一个消费者消费，其他消费者则不能染指。在 Kafka 中实现这种 P2P 模型的方法就是引入了**消费者组**(Consumer Group)。

所谓的消费者组，指的是多个消费者实例共同组成一个组来消费一组主题。这组主题中的每个分区都只会被组内的一个消费者实例消费，其他消费者实 例不能消费它。


为什么要引入消费者组呢?主要是为了提升消费者端的吞吐量。多个消费者实例同时消费，加速整个消费端的吞吐量(TPS)。


假设组内某个实例挂掉了，Kafka 能够自动检测到，然后把这个Failed 实例之前负责的分区转移给其他活着的消费者。这个过程就是 Kafka 中大名鼎鼎的“**重平衡**”(Rebalance)。嗯，其实既是大名鼎鼎，也是臭名昭著，因为由重平衡引发的消费者 问题比比皆是。事实上，目前很多重平衡的 Bug 社区都无力解决。Rebalance 是 Kafka 消费者端实现高可用的重要手段。


每个消费者在消费消息的过程中必然需要有个字段记录它当前消费到了分区的哪个位置上， 这个字段就是消费者位移(Consumer Offset)。

上面的“位移”表征的是分区内的消息位置，它是不变的，即一旦消息被成功写入 到一个分区上，它的位移值就是固定的了。而消费者位移则不同，它可能是随时变化的，毕 竟它是消费者消费进度的指示器嘛。



**kafka是按照什么规则将消息划分到各个分区的?**

>如果producer指定了要发送的目标分区，消息自然是去到那个分区;否则就按照 producer端参数partitioner.class指定的分区策略来定;如果你没有指定过partitioner.class，那 么默认的规则是:看消息是否有key，如果有则计算key的murmur2哈希值%topic分区数;如果 没有key，按照轮询的方式确定分区。


**Kafka的follower副本为什么不像redis、kafka那样提供读写分离功能？**

- kafka客户端读操作是会移动broker中分区的offset，如果副本提供读服务，副本更变 offset，再回同步领导副本，数据一致性就无法得到保障。 follower 提供读服务会提高数据一致性保证的复杂度。
- kafka集群可以通过增加partition及broker的方式实现负载均衡，并不需要从follower


## Kafka角色定位

Apache Kafka 是消息引擎系统，也是一个 分布式流处理平台(Distributed Streaming Platform)。

- 最初定位： 分布式、分区化且带备份功能的 提交日志(Commit Log)服务。


LinkedIn 最开始有强烈的数据强实时处理方面的需求，其内部的诸多子系统要执行多种类型的数据处理与分析，主要包括业务系统和应用程序性能监控，以及用户行为数据处理等。

当时他们碰到的主要问题包括:
- 数据正确性不足。因为数据的收集主要采用轮询(Polling)的方式，如何确定轮询的间 隔时间就变成了一个高度经验化的事情。虽然可以采用一些类似于启发式算法 (Heuristic)来帮助评估间隔时间值，但一旦指定不当，必然会造成较大的数据偏差。

- 系统高度定制化，维护成本高。各个业务子系统都需要对接数据收集模块，引入了大量的定制开销和人工成本。


为了解决这些问题，LinkedIn 工程师尝试过使用 ActiveMQ 来解决这些问题，但效果并不 理想。显然需要有一个“大一统”的系统来取代现有的工作方式，而这个系统就是 Kafka。

Kafka 在设计之初就旨在提供三个方面的特性:
- 提供一套 API 实现生产者和消费者; 
- 降低网络传输和磁盘存储开销; 
- 实现高伸缩性架构。


作为流处理平台，Kafka 与其他主流大数据流式计算框架相比，优势在哪里呢?

- 第一点是更容易实现端到端的正确性(Correctness)。Google 大神 Tyler 曾经说过，流处理要最终替代它的“兄弟”批处理需要具备两点核心优势: 要实现**正确性**和**提供能够推导时间的工具**。实现正确性是流处理能够匹敌批处理的基石。
- 实现正确性的基石则是要求框架能提供精确一次处理语义，即处理一条消息有且只有一次机 会能够影响系统状态。目前主流的大数据流处理框架都宣称实现了精确一次处理语义，但这是有限定条件的，即它们只能实现框架内的精确一次处理语义，无法实现端到端的。
- 因为当这些框架与外部消息引擎系统结合使用时，它们无法影响到外部系统的处理语义，所以
  - 如果你搭建了一套环境使得 Spark 或 Flink 从 Kafka 读取消息之后进行 有状态的数据计算，最后再写回 Kafka，那么你只能保证在 Spark 或 Flink 内部，这条消息对于状态的影响只有一次。但是计算结果有可能多次写入到 Kafka，因为它们不能控制 Kafka 的语义处理。
  - 相反地，Kafka 则不是这样，因为所有的数据流转和计算都在 Kafka 内部完成，故 Kafka 可以实现端到端的精确一次处理语义。


## Kafka版本选择

---
# 二、客户端

## 生产者

### 分区机制


### 压缩算法


### 无消息丢失配置



### 高级功能


### TCP连接管理


### 幂等性生产与事务



## 消费者

### 消费者组


### 位移主题


### Rebalance


### 位移提交



### 异常处理


### 多线程开发实例


### TCP连接管理


### group监控

---
# Kafka原理

## 备份机制


## 请求处理

## Rebalance全流程解析


## Controller


## 高水位

---
# 运维与监控


## 主题管理

## 动态配置


## 消费组位移管理


## KafkaAdminClient


## 认证机制


## MirrorMaker


## 监控框架


## 授权管理

## Kafka调优


## 流处理应用搭建实例


---
# 高级Kafka应用

## Kafka Stream


## Kafka DSL开发


## 应用实例