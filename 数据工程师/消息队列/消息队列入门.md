
# 入门介绍

## 为什么要使用MQ
1)**解耦**:A 系统发送数据到 BCD 三个系统，通过接口调用发送。如果 E 系统也要这个数据呢?那 如果 C 系统现在不需要了呢?
>就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦。

(2)**异步**: A 系统接收一个请求，需要在自己本地写库，还需要在 BCD 三个系统写库，自己本地 写库要 3ms，BCD 三个系统分别写库要 300ms、450ms、200ms。

(3)**削峰**:减少高峰时期对服务器压力。


**缺点**

- **系统可用性降低**：万一 MQ 挂了，MQ一挂，整套系统崩溃，GG?
- **系统复杂度提高**： 硬生生加个 MQ 进来，你怎么保证消息没有重复消费?怎么处理消息丢失的情况? 怎么保证消息传递的顺序性?问题一大堆。
- **一致性问题**： A 系统处理完了直接返回成功了，人都以为你这个请求就成功了;但是问题是，要是 BCD 三个系统那里，BD 两个系统写库成功了，结果 C 系统写库失败了，咋整?你这数据就不一致 了。


## Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别?

- 吞吐：kafka和RocketMQ支撑高吞吐，ActiveMQ和RabbitMQ比他们低一个数量级。
- 延迟：RabbitMQ是最低的

1. 社区活跃度
2. 持久化消息功能比较
   1. Kafka、ActiveMq 和RabbitMq 都支持。
3. 综合技术实现
   1. 指标：可靠性、灵活的路由、集群、事务、高可用的队列、消息排序、问题追踪、可视化管理工具、插件系统等等。
   2. RabbitMq / Kafka 最好，ActiveMq 次之，ZeroMq 最差。当然ZeroMq 也可以做到，不过自己必须手动写代码实现，代码量不小。
4. 高并发
   1. RabbitMQ 最高，原因是它的实现语言是天生具备高并发高可用的erlang 语言。
5. 比较关注的比较， RabbitMQ 和 Kafka
   1. RabbitMq 比Kafka 成熟，在可用性上，稳定性上，可靠性上， RabbitMq 胜于 Kafka (理论 上)。
   2. Kafka 的定位主要在日志等方面， 因为Kafka 设计的初衷就是处理日志的，可以看做是一个 日志(消息)系统一个重要组件。
   3. Kafka高吞吐、TPS


## 如何保证高可用的

 **RabbitMQ**：
 - 普通集群模式：你创建的 queue，只会放在一个 RabbitMQ 实例上，但是每个实例都同步 queue 的元数据。
  >这方案主要是提 高吞吐量的，就是说让集群中多个节点来服务某个 queue 的读写操作。
 - 镜像集群模式: 所谓的 RabbitMQ 的高可用模式. 源数据和消息都存在多个实例上。每个 RabbitMQ 节点都有这个 queue 的一个完整镜像，包含 queue 的全部数据。
  >**坏处**：性能开销也太大了吧，消息需要同步到所有机器上，导 致网络带宽压力和消耗很重!RabbitMQ 一个 queue 的数据都是放在一个节点里的，镜像集群下， 也是每个节点都放这个 queue 的完整数据。


**Kafka**:

- **多节点**： 由多个 broker 组成，每个 broker 是一个节点;
- **分片**： 你创建一个 topic，这个 topic 可以划分为多个 partition，每个 partition 可以存在于不同的 broker 上，每个 partition 就放一部分数据。这就是天然的分布式消息队列，就是说一个 topic 的数据，是分散放在 多个机器上的，每个机器就放一部分数据。
- **副本**： Kafka 会均匀地将一个 partition 的所有 replica 分布在不同的机器上，这样才可以提高容错性。


## 如何保证消息的可靠传输？ 如果消息丢了怎么办？

### 生产者丢失

**现象**： 
生产者将数据发送到 RabbitMQ 的时候，可能数据就在半路给搞丢，比如网络问题。 


**解决思路**： 

1. **事务机制**： 可以选择用 RabbitMQ 提供的**事务功能**，就是生产者发送数据之前开启 RabbitMQ 事务channel.txSelect，然后发送消息：
   - 如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到**异常报错**，此时就可以回滚事务channel.txRollback，然后重试发送消息; 
   - 如果收到了消息，那么可以提交事务channel.txCommit。吞吐量会下来，因为太耗性能。
   - **事务机制是同步的**

2. **开启confirm模式**： 开启后，每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中：
   - RabbitMQ 会给回传一个ack消息，表示收到了。 
   - 如果没能处理，会回调你一个 nack接口，告诉你这个消息接收失败，你可以重试。
   - 可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。（可能导致重复消费）
   - **confirm机制是异步的**， 所以一般在生产者这块避免数据丢失，都 是用confirm机制的。

### 消息队列中丢失

MQ机器挂了

**解决思路**

- 必须开启 RabbitMQ 的持久化
- 注意： 持久化可以跟生产者那边的confirm机制配合起来，**只有消息被持久化到磁盘之后，才会通知生产者ack了**，所以哪怕是在持久化到磁盘之前， RabbitMQ 挂了，数据丢了，生产者收不到ack，你也是**可以自己重发**的。


### 消费端丢失

消费进程挂了或者重启了。


**解决思路**：

- 用 RabbitMQ 提供的ack机制: 关闭 RabbitMQ 的自动ack，可以通过一个 api 来调用就行，然后每次你自己代码里确 保处理完的时候，再在程序里ack一把。这样的话，如果你还没处理完，不就没有ack?那 RabbitMQ 就认为你还没处理完，这个时候 RabbitMQ 会把这个消费分配给别的 consumer 去处 理，消息是不会丢的。


### 如何保证消息顺序性

**场景**: RabbitMQ:一个 queue，多个 consumer，顺序就错乱了;

**解决**: 
- 拆分多个queue，每个queue对应一个消费者。 缺点就是queue多一些。
- 一个queue对应一个consumer， 然后consumer内部用内存队列排队，发给底层的worker来处理。


### 场景题目

1. 如何解决消息队列的**延时以及过期失效**问题?

假设你用的是 RabbitMQ， RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。

**大量数据搞丢，这问题很严重。**

业务低峰期，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。

如果需要快速修复呢？


2. 有几百万消息**持续积**压几小时，说说怎么解决?

- 消息积压处理办法: 临时紧急扩容
  - 确认消费程序是否有问题，先修复 consumer 的问题，确保其恢复消费速度。
  - 然后将现有consumer都停掉？
  - 新建一个topic，partition扩大10倍，建立10倍queue
  - **写一个临时分发数据的consumer程序**， 部署去消费原来的topic积压的数据，消费之后不做耗时的处理，直接均匀 轮询写入临时建立好的 10 倍数量的 queue。
  - 临时征用 10 倍的机器来部署 consumer，每一 批 consumer 消费一个临时 queue 的数据。


3. 消息**队列满**了以后该怎么处理? 

你临时写程序，接入数据来消费，消费一个丢弃一个，都不要了，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。

MQ不能直接丢弃消息嘛？


## 设计一个消息队列，会如何设计？ 

1. 可伸缩： 快速扩容， 分布式
2. 高可用
3. 持久化
4. 数据一致性


## 05 | 如何确保消息不会丢失?


### 检测消息丢失的方法

我们可以利用消息队列的有序性来验证是否有消息丢失。原理非常简单，在 Producer 端， 我们给每个发出的消息附加一个连续递增的序号，然后在 Consumer 端来检查这个序号的 连续性。

- 如果检测到序号不连续，那就是丢消息了。还可 以通过缺失的序号来确定丢失的是哪条消息，方便进一步排查原因。


大多数消息队列的客户端都支持拦截器机制，你可以利用这个拦截器机制，在 Producer 发 送消息之前的拦截器中将序号注入到消息中,在 Consumer 收到消息的拦截器中检测序号 的连续性。 好处：不会侵入业务代码逻辑，稳定后还能关闭。


**难点**

- 像 `Kafka` 和 `RocketMQ` 这样的消息队列，它是**不保证在 Topic 上的严格顺序**的， 只能**保证分区上的消息是有序的**：
  >所以我们在发消息的时候必须要指定分区，并且，在每个分区单独检测消息序号的连续性。

- 如果你的系统中 **Producer 是多实例**的，由于并不好协调多个Producer 之间的发送顺序， 所以也需要每个 Producer 分别生成各自的消息序号，并且需要附加上 Producer 的标识， 在 Consumer 端**按照每个Producer分别来检测序号的连续性**。


- Consumer 实例的数量最好和分区数量一致，做到 Consumer 和分区一一对应，这样会比较方便地在 Consumer 内检测消息序号的连续性。



### 确保消息可靠传递

整个消息从生产到消费的过程中，哪些地方可能会导致丢消息，以及应该如何避免消息丢失。

- 生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 存储阶段: 
- 存储阶段： 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。
- 消费阶段： Consumer从Broker上拉取消息，经过网络传输发送到 Consumer 上。



1. **生产阶段**

在生产阶段，消息队列通过最常用的请求确认机制，来保证消息的可靠传递: 客户端发消息到Broker，Broker收到消息后给客户端返回一个确认响应， 客户端收到响应，完成一次正常消息发送。

- 只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失
- 有些消息队列在长时间没收到发送确认响应后，会自动重试，如果重试再失败，就会**以返回值或者 异常的方式**告知用户。 **正确处理返回值或者捕获异常，就可以保证这个阶段的消息不会丢失。**
- 异步发送时，则需要在回调方法里进行检查。这个地方是需要特别注意的，**很多丢消息的原
因**就是，我们使用了异步发送，却**没有在回调中检查发送结果**。


2. **存储阶段**

正常运行就不会丢消息，但如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，还是可能会丢失消息的。

**如果对消息的可靠性要求非常高，可以通过配置 Broker 参数来避免因为宕机丢消息。**

- 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息**写入磁盘后再给Producer返回确认响应**。
  >例如，在 RocketMQ 中，需要将刷盘方式 flushDiskType 配
置为 SYNC_FLUSH 同步刷盘。

- 如果是 Broker 是由多个节点组成的集群，需要将 Broker 集群配置成: 至少将消息发送到
2 个以上的节点，再给客户端回复发送确认响应。这样当某个 Broker 宕机时，其他的Broker 可以替代宕机的 Broker，也不会发生消息丢失。


3. **消费阶段**

类似生产阶段，通过确认机制保证消息的可靠传递， 消费客户端从Broker拉取消息后，执行用户业务逻辑成功后，才会给Broker发送消费确认消息。  

- 如果Broker长时间内没收到响应，下次拉消息的时候再次返回同一条消息，确保不在网络传输过程中丢失。

- 不要在收到消息后就立即发送消费确认，而是应该在执完所有消费业务逻辑之后，再发送消费确认。


## 06 | 如何处理消费过程中的重复消息?

**消息重复的情况必然存在**

在 MQTT 协议中，给出了三种**传递消息时**能够提供的**服务质量标准**，这三种服务质量从低 到高依次是:

- A**t most once**: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，**允许丢消息**。一般都是一些**对消息可靠性要求不太高的监控场景**使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。


- **At least once**: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消 息，但是**允许有少量重复消息**出现。


- Exactly once:恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是**最高的等级。**

>在 Kafka 中，事务和 Excactly once 主要是为了配合流计算使用的特性，Kafka 支持的“Exactly once”和我们刚刚提到的消息传递的服务质量标准“Exactly once”是不一样的.